{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom keras.models import Sequential, Model, model_from_json\n# Importing required libraries \nimport keras \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:27:21.736996Z","iopub.execute_input":"2022-05-25T08:27:21.737826Z","iopub.status.idle":"2022-05-25T08:27:29.170207Z","shell.execute_reply.started":"2022-05-25T08:27:21.737697Z","shell.execute_reply":"2022-05-25T08:27:29.168793Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Audio\nimport librosa\nimport librosa.display\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:27:52.429288Z","iopub.execute_input":"2022-05-25T08:27:52.429640Z","iopub.status.idle":"2022-05-25T08:27:53.968070Z","shell.execute_reply.started":"2022-05-25T08:27:52.429603Z","shell.execute_reply":"2022-05-25T08:27:53.966350Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"paths = []\nlabels = []\nfor dirname, _, filenames in os.walk('/kaggle/input/toronto-emotional-speech-set-tess'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        labels.append(label.lower())\nprint('Dataset is Loaded')\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:27:58.556658Z","iopub.execute_input":"2022-05-25T08:27:58.557834Z","iopub.status.idle":"2022-05-25T08:27:59.808283Z","shell.execute_reply.started":"2022-05-25T08:27:58.557764Z","shell.execute_reply":"2022-05-25T08:27:59.806948Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tess_df = pd.DataFrame()\ntess_df['label'] = labels\ntess_df['speech'] = paths\ntess_df.label.replace({'ps':'surprise'}, inplace=True)\ntess_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:28:02.869370Z","iopub.execute_input":"2022-05-25T08:28:02.869765Z","iopub.status.idle":"2022-05-25T08:28:02.902222Z","shell.execute_reply.started":"2022-05-25T08:28:02.869736Z","shell.execute_reply":"2022-05-25T08:28:02.901205Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tess_df['label'].value_counts()\nsns.countplot(tess_df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:28:06.496627Z","iopub.execute_input":"2022-05-25T08:28:06.496962Z","iopub.status.idle":"2022-05-25T08:28:06.690458Z","shell.execute_reply.started":"2022-05-25T08:28:06.496925Z","shell.execute_reply":"2022-05-25T08:28:06.689744Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"Ravdess=\"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\nravdess_directory_list = os.listdir(Ravdess)\n\nfile_emotion = []\nfile_path = []\nfor dir in ravdess_directory_list:\n    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n    actor = os.listdir(Ravdess + dir)\n    for file in actor:\n        part = file.split('.')[0]\n        part = part.split('-')\n        # third part in each file represents the emotion associated to that file.\n        file_emotion.append(int(part[2]))\n        file_path.append(Ravdess + dir + '/' + file)\n        \n# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['label'])\n\n# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['speech'])\nRavdess_df = pd.concat([emotion_df, path_df], axis=1)\n\n# changing integers to actual emotions.\nRavdess_df.label.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\nRavdess_df=Ravdess_df[Ravdess_df['label'] != 'calm']\nRavdess_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:38:25.037305Z","iopub.execute_input":"2022-05-25T08:38:25.037631Z","iopub.status.idle":"2022-05-25T08:38:25.093876Z","shell.execute_reply.started":"2022-05-25T08:38:25.037593Z","shell.execute_reply":"2022-05-25T08:38:25.092841Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"Ravdess_df['label'].value_counts()\nsns.countplot(Ravdess_df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:38:28.637185Z","iopub.execute_input":"2022-05-25T08:38:28.638008Z","iopub.status.idle":"2022-05-25T08:38:28.822938Z","shell.execute_reply.started":"2022-05-25T08:38:28.637960Z","shell.execute_reply":"2022-05-25T08:38:28.821899Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"SAVEE=\"../input/surrey-audiovisual-expressed-emotion-savee/ALL/\"\ndir_list = os.listdir(SAVEE)\n\nemotion=[]\npath = []\nfor i in dir_list:\n    if i[-8:-6]=='_a':\n        emotion.append('angry')\n    elif i[-8:-6]=='_d':\n        emotion.append('disgust')\n    elif i[-8:-6]=='_f':\n        emotion.append('fear')\n    elif i[-8:-6]=='_h':\n        emotion.append('happy')\n    elif i[-8:-6]=='_n':\n        emotion.append('neutral')\n    elif i[-8:-6]=='sa':\n        emotion.append('sad')\n    elif i[-8:-6]=='su':\n        emotion.append('surprise')\n    path.append(SAVEE + i)\n\n\n    \nSAVEE_df = pd.DataFrame(emotion, columns = ['label'])\nSAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['speech'])], axis = 1)\nSAVEE_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:55:19.367553Z","iopub.execute_input":"2022-05-25T08:55:19.368291Z","iopub.status.idle":"2022-05-25T08:55:19.395164Z","shell.execute_reply.started":"2022-05-25T08:55:19.368245Z","shell.execute_reply":"2022-05-25T08:55:19.393549Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"SAVEE_df['label'].value_counts()\nsns.countplot(SAVEE_df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:31:04.913379Z","iopub.execute_input":"2022-05-25T08:31:04.914643Z","iopub.status.idle":"2022-05-25T08:31:05.084324Z","shell.execute_reply.started":"2022-05-25T08:31:04.914580Z","shell.execute_reply":"2022-05-25T08:31:05.083382Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#voting set\n\ncremad=\"/kaggle/input/cremad/AudioWAV/\"\ncrema_directory_list = os.listdir(cremad)\n\nfile_emotion = []\nfile_path = []\n\nfor file in crema_directory_list:\n    # storing file paths\n    file_path.append(cremad + file)\n    # storing file emotions\n    part=file.split('_')\n    if part[2] == 'SAD':\n        file_emotion.append('sad')\n    elif part[2] == 'ANG':\n        file_emotion.append('angry')\n    elif part[2] == 'DIS':\n        file_emotion.append('disgust')\n    elif part[2] == 'FEA':\n        file_emotion.append('fear')\n    elif part[2] == 'HAP':\n        file_emotion.append('happy')\n    elif part[2] == 'NEU':\n        file_emotion.append('neutral')\n    else:\n        file_emotion.append('Unknown')\n        \n# dataframe for emotion of files\n\nemotion_df = pd.DataFrame(file_emotion, columns=['label'])\npath_df = pd.DataFrame(file_path, columns=['speech'])\ncrema_df = pd.concat([emotion_df, path_df], axis=1)\n\ncrema_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:51:31.197248Z","iopub.execute_input":"2022-05-25T08:51:31.197549Z","iopub.status.idle":"2022-05-25T08:51:31.411001Z","shell.execute_reply.started":"2022-05-25T08:51:31.197517Z","shell.execute_reply":"2022-05-25T08:51:31.409019Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"crema_df['label'].value_counts()\nsns.countplot(crema_df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:55:30.048890Z","iopub.execute_input":"2022-05-25T08:55:30.049212Z","iopub.status.idle":"2022-05-25T08:55:30.201066Z","shell.execute_reply.started":"2022-05-25T08:55:30.049175Z","shell.execute_reply":"2022-05-25T08:55:30.200348Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#train dbs -> ravdess+tess\n#manual test db -> cremad \n\ndf = pd.concat([Ravdess_df, tess_df,SAVEE_df,crema_df], axis = 0)\ndf.to_csv(\"df.csv\",index=False)\ndf.head()\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:52:05.815950Z","iopub.execute_input":"2022-05-25T08:52:05.816237Z","iopub.status.idle":"2022-05-25T08:52:05.895336Z","shell.execute_reply.started":"2022-05-25T08:52:05.816206Z","shell.execute_reply":"2022-05-25T08:52:05.894498Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()\nsns.countplot(df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:52:08.953212Z","iopub.execute_input":"2022-05-25T08:52:08.953505Z","iopub.status.idle":"2022-05-25T08:52:09.113020Z","shell.execute_reply.started":"2022-05-25T08:52:08.953471Z","shell.execute_reply":"2022-05-25T08:52:09.112117Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def waveplot(data, sr, emotion):\n    plt.figure(figsize=(10,4))\n    plt.title(emotion, size=20)\n    librosa.display.waveshow(data, sr=sr)\n    plt.ylabel(\"Amplitude\")\n    plt.show()\n    \ndef spectogram(data, sr, emotion):\n    x = librosa.stft(data)\n    xdb = librosa.amplitude_to_db(abs(x))\n    plt.figure(figsize=(11,4))\n    plt.title(emotion, size=20)\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:53:30.393216Z","iopub.execute_input":"2022-05-25T08:53:30.393484Z","iopub.status.idle":"2022-05-25T08:53:30.399646Z","shell.execute_reply.started":"2022-05-25T08:53:30.393454Z","shell.execute_reply":"2022-05-25T08:53:30.398601Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['label']==emotion])[700]\nprint(path)\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:53:33.023190Z","iopub.execute_input":"2022-05-25T08:53:33.023729Z","iopub.status.idle":"2022-05-25T08:53:33.607491Z","shell.execute_reply.started":"2022-05-25T08:53:33.023661Z","shell.execute_reply":"2022-05-25T08:53:33.606472Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['label']==emotion])[700]\nprint(path)\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:53:36.031092Z","iopub.execute_input":"2022-05-25T08:53:36.031553Z","iopub.status.idle":"2022-05-25T08:53:37.152054Z","shell.execute_reply.started":"2022-05-25T08:53:36.031501Z","shell.execute_reply":"2022-05-25T08:53:37.151450Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"emotion = 'surprise'\npath = np.array(df['speech'][df['label']==emotion])[700]\nprint(path)\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:53:39.589642Z","iopub.execute_input":"2022-05-25T08:53:39.590393Z","iopub.status.idle":"2022-05-25T08:53:40.209880Z","shell.execute_reply.started":"2022-05-25T08:53:39.590360Z","shell.execute_reply":"2022-05-25T08:53:40.208934Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:55:51.814981Z","iopub.execute_input":"2022-05-25T08:55:51.815371Z","iopub.status.idle":"2022-05-25T08:55:51.820095Z","shell.execute_reply.started":"2022-05-25T08:55:51.815335Z","shell.execute_reply":"2022-05-25T08:55:51.818996Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\n\nX_mfcc\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T08:55:56.580675Z","iopub.execute_input":"2022-05-25T08:55:56.581031Z","iopub.status.idle":"2022-05-25T09:13:12.969621Z","shell.execute_reply.started":"2022-05-25T08:55:56.580987Z","shell.execute_reply":"2022-05-25T09:13:12.968786Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X = [x for x in X_mfcc]\nX = np.array(X)\nX.shape\n\nX = np.expand_dims(X, -1) #to thelei etsi to modeloo\nX.shape\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:13:45.066053Z","iopub.execute_input":"2022-05-25T09:13:45.066369Z","iopub.status.idle":"2022-05-25T09:13:45.089209Z","shell.execute_reply.started":"2022-05-25T09:13:45.066336Z","shell.execute_reply":"2022-05-25T09:13:45.087270Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder #gia kathe input vazei ti einai to label tou\nenc = LabelEncoder()\nyi = enc.fit_transform(df[['label']])\nlabelss=enc.classes_\nprint(labelss)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:13:47.981594Z","iopub.execute_input":"2022-05-25T09:13:47.982317Z","iopub.status.idle":"2022-05-25T09:13:48.001584Z","shell.execute_reply.started":"2022-05-25T09:13:47.982249Z","shell.execute_reply":"2022-05-25T09:13:48.000987Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder #gia kathe input vazei ti einai to label tou\n\n\ny = df['label'].values\nencoder = OneHotEncoder() \ny = encoder.fit_transform(np.array(y).reshape(-1,1)).toarray()\nprint(y[4])\nprint(np.shape(y))\nprint(labelss)\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:13:52.884614Z","iopub.execute_input":"2022-05-25T09:13:52.884982Z","iopub.status.idle":"2022-05-25T09:13:52.912078Z","shell.execute_reply.started":"2022-05-25T09:13:52.884944Z","shell.execute_reply":"2022-05-25T09:13:52.910939Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()\nsns.countplot(df['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:21:35.016154Z","iopub.execute_input":"2022-05-25T10:21:35.016701Z","iopub.status.idle":"2022-05-25T10:21:35.199788Z","shell.execute_reply.started":"2022-05-25T10:21:35.016660Z","shell.execute_reply":"2022-05-25T10:21:35.199150Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:14:03.893055Z","iopub.execute_input":"2022-05-25T09:14:03.893336Z","iopub.status.idle":"2022-05-25T09:14:03.909910Z","shell.execute_reply.started":"2022-05-25T09:14:03.893306Z","shell.execute_reply":"2022-05-25T09:14:03.908616Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential([\n    LSTM(256, return_sequences=False, input_shape=(x_train.shape[1], 1)),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax') #gia binary vazei sigmoid edw exoume 7 diaforetika labels omws\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:14:08.163314Z","iopub.execute_input":"2022-05-25T09:14:08.163928Z","iopub.status.idle":"2022-05-25T09:14:08.696797Z","shell.execute_reply.started":"2022-05-25T09:14:08.163884Z","shell.execute_reply":"2022-05-25T09:14:08.695596Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.callbacks import ReduceLROnPlateau\n\nrlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nhistory=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])\n#psaksimo gia orologies (mexri na treksei i malakia)\n#epoch: poses fores perna ena olokliro dataset apo to neurwniko->theleis polla gia na ginoun updates sta weights\n#dropout: to tuxaio skipparisma kombwn sta epimerous layers wste na epiluthei to thema overfitting/underfitting\n#batch_size: pws spaei ana iteration to dataset (diladi se stoivades twn 64)\n#https://github.com/christianversloot/machine-learning-articles/blob/main/what-is-dropout-reduce-overfitting-in-your-neural-networks.md\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:14:11.585788Z","iopub.execute_input":"2022-05-25T09:14:11.586172Z","iopub.status.idle":"2022-05-25T09:32:19.570761Z","shell.execute_reply.started":"2022-05-25T09:14:11.586130Z","shell.execute_reply":"2022-05-25T09:32:19.569307Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"type(history)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:31:47.767723Z","iopub.execute_input":"2022-05-05T18:31:47.768278Z","iopub.status.idle":"2022-05-05T18:31:47.774028Z","shell.execute_reply.started":"2022-05-05T18:31:47.76824Z","shell.execute_reply":"2022-05-05T18:31:47.77321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = list(range(50))\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, label='train accuracy')\nplt.plot(epochs, val_acc, label='val accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:32:30.146808Z","iopub.execute_input":"2022-05-25T09:32:30.147098Z","iopub.status.idle":"2022-05-25T09:32:30.343388Z","shell.execute_reply.started":"2022-05-25T09:32:30.147067Z","shell.execute_reply":"2022-05-25T09:32:30.342100Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs, loss, label='train loss')\nplt.plot(epochs, val_loss, label='val loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:32:36.959396Z","iopub.execute_input":"2022-05-25T09:32:36.959750Z","iopub.status.idle":"2022-05-25T09:32:37.145391Z","shell.execute_reply.started":"2022-05-25T09:32:36.959692Z","shell.execute_reply":"2022-05-25T09:32:37.144864Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"accuracy_final = sum(val_acc)/50\nprint(accuracy_final*100)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:32:43.252010Z","iopub.execute_input":"2022-05-25T09:32:43.252279Z","iopub.status.idle":"2022-05-25T09:32:43.258067Z","shell.execute_reply.started":"2022-05-25T09:32:43.252249Z","shell.execute_reply":"2022-05-25T09:32:43.257238Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n#encoder=OneHotEncoder()\npred_test = model.predict(x_test)\ny_pred = encoder.inverse_transform(pred_test)\ny_test = encoder.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:32:54.744538Z","iopub.execute_input":"2022-05-25T09:32:54.744830Z","iopub.status.idle":"2022-05-25T09:32:58.110228Z","shell.execute_reply.started":"2022-05-25T09:32:54.744797Z","shell.execute_reply":"2022-05-25T09:32:58.108679Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (12, 10))\ncm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\nsns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\nplt.title('Confusion Matrix', size=20)\nplt.xlabel('Predicted Labels', size=14)\nplt.ylabel('Actual Labels', size=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:33:01.442532Z","iopub.execute_input":"2022-05-25T09:33:01.442889Z","iopub.status.idle":"2022-05-25T09:33:01.933662Z","shell.execute_reply.started":"2022-05-25T09:33:01.442848Z","shell.execute_reply":"2022-05-25T09:33:01.932768Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:33:24.498399Z","iopub.execute_input":"2022-05-25T09:33:24.498804Z","iopub.status.idle":"2022-05-25T09:33:24.588476Z","shell.execute_reply.started":"2022-05-25T09:33:24.498771Z","shell.execute_reply":"2022-05-25T09:33:24.587799Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\nmodel_name = 'Emotion_Model.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Save model and weights at %s ' % model_path)\n\n# Save the model to disk\nmodel_json = model.to_json()\nwith open(\"model_json.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:33:10.857950Z","iopub.execute_input":"2022-05-25T09:33:10.858248Z","iopub.status.idle":"2022-05-25T09:33:10.924033Z","shell.execute_reply.started":"2022-05-25T09:33:10.858214Z","shell.execute_reply":"2022-05-25T09:33:10.923180Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"json_file = open('/kaggle/working/model_json.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"/kaggle/working/saved_models/Emotion_Model.h5\")\nprint(\"Loaded model from disk\")\n\n# the optimiser\nloaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T09:33:13.732104Z","iopub.execute_input":"2022-05-25T09:33:13.732900Z","iopub.status.idle":"2022-05-25T09:33:14.099803Z","shell.execute_reply.started":"2022-05-25T09:33:13.732864Z","shell.execute_reply":"2022-05-25T09:33:14.098861Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#voting_session\ndef voting(real_emotion):\n    test_df=SAVEE_df\n    test_df=test_df['speech'][test_df['label']==real_emotion]\n    test_df=test_df.sample(n=10)\n    test_df.head()\n    test_arr = np.array(test_df)\n    sum_final=np.zeros(7)\n    voting_sess=[]\n    for i in range(int(test_arr.shape[0])):\n        XFCC1=extract_mfcc(test_arr[i])\n        X1=np.array(XFCC1)\n        X1 = np.expand_dims(X1, -1) #to thelei etsi to modelo\n\n        newdf = pd.DataFrame(data=X1).T\n        newdf\n\n        newdf= np.expand_dims(newdf, axis=2)\n        newpred = loaded_model.predict(newdf, \n                             batch_size=16, \n                             verbose=1)\n\n        final = newpred.argmax(axis=1)\n        final = final.astype(int).flatten()\n        voting_sess.append(final[0])\n\n        sum_final+=newpred[0]\n    sum_final=(sum_final/10)*100\n    return(sum_final,voting_sess)\n\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:56:37.688609Z","iopub.execute_input":"2022-05-25T10:56:37.688937Z","iopub.status.idle":"2022-05-25T10:56:37.700858Z","shell.execute_reply.started":"2022-05-25T10:56:37.688905Z","shell.execute_reply":"2022-05-25T10:56:37.700055Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"sum_final,voting_sess=voting('sad')\n\ndiscr_votes=[]\n\nanalog_data=[]\nanalog_data.append(sum_final)\nanalog_data.append(labelss)\n\nanalog_df = pd.DataFrame(analog_data).transpose()\nanalog_df.columns=['mean %', 'emotions']\nprint(analog_df)\n\nplt.bar(labelss,sum_final)\nplt.title(\"Mean Percentage voting\")\nplt.show()\n\nprint(np.shape(voting_sess))\nfor i in range(int(np.shape(voting_sess)[0])):\n    discr_votes.append(labelss[int(voting_sess[i])])\n\n\ndiscr_df = pd.DataFrame(discr_votes, columns=['votes'])\n\nprint(discr_df)\n\n\ndiscr_df['votes'].value_counts()\nsns.countplot(discr_df['votes'])\nplt.title('discrete voting results')\n\n\n\n\n\n    \n    \n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T10:56:45.778124Z","iopub.execute_input":"2022-05-25T10:56:45.779296Z","iopub.status.idle":"2022-05-25T10:56:47.748256Z","shell.execute_reply.started":"2022-05-25T10:56:45.779240Z","shell.execute_reply":"2022-05-25T10:56:47.747529Z"},"trusted":true},"execution_count":176,"outputs":[]}]}